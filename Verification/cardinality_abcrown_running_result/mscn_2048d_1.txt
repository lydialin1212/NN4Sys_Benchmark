Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: matrix
  deterministic: false
  double_fp: false
  loss_reduction_func: max
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: false
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: false
  csv_name: null
  results_file: out.txt
  root_path: ''
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "default_optimizer")'
  no_batchdim_buffers: false
  save_output: false
  output_file: out.pkl
model:
  name: null
  path: null
  onnx_path: ../Benchmarks/onnx/mscn_2048d.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
  onnx_vnnlib_joint_optimization_flags: none
  check_optmized: false
  flatten_final_output: false
  optimize_graph: null
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: ../Benchmarks/vnnlib/mscn_2048d_1.vnnlib
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 50
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: forward+backward
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    apply_output_constraints_to: []
    disable_optimization: []
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 10
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: false
bab:
  initial_max_domains: 100000
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: naive
    candidates: 3
    reduceop: min
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      shortlist_size: 500
      loose_tanh_threshold: null
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: true
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: .inf
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 30
  pgd_batch_size: 100000000
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: default_adv_saver
  early_stop_condition: default_early_stop_condition
  adv_example_finalizer: default_adv_example_finalizer
  pgd_loss: default_pgd_loss
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: attack_with_general_specs
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Tue Oct 17 03:39:16 2023 on srg07
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx ../Benchmarks/onnx/mscn_2048d.onnx
Using vnnlib ../Benchmarks/vnnlib/mscn_2048d_1.vnnlib
Precompiled vnnlib file found at ../Benchmarks/vnnlib/mscn_2048d_1.vnnlib.compiled
Loading onnx ../Benchmarks/onnx/mscn_2048d.onnx wih quirks {}
Attack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.1143636479973793, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[0.74551517]], device='cuda:0')
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[0.75066745],
         [0.75066745]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[0.01546425, 0.00021064, 0.00117081, 0.02292985, 0.00040829,
          0.02139658, 0.02344352, 0.00012171, 0.00029659, 0.00316042]]],
       device='cuda:0')
number of violation:  0
Attack finished in 85.3023 seconds.
PGD attack failed
Total VNNLIB file length: 1000, max property batch size: 100000, total number of batches: 1

Properties batch 0, size 1000
Remaining timeout: 272.18439197540283
##### Instance 0 first 10 spec matrices: 
tensor([[[ 1.]],

        [[-1.]],

        [[ 1.]],

        [[-1.]],

        [[ 1.]],

        [[-1.]],

        [[ 1.]],

        [[-1.]],

        [[ 1.]],

        [[-1.]]], dtype=torch.float64)
thresholds: tensor([ 0.73520321, -0.75087810,  0.65474606, -0.67884672,  0.68321770,
        -0.70502257,  0.82221049, -0.84577572,  0.71905011, -0.72250712],
       device='cuda:0') ######
Model: BoundedModule(
  (/0): BoundInput(name=/0, inputs=[], perturbed=False)
  (/41): BoundParams(name=/41, inputs=[], perturbed=False)
  (/42): BoundParams(name=/42, inputs=[], perturbed=False)
  (/43): BoundParams(name=/43, inputs=[], perturbed=False)
  (/44): BoundParams(name=/44, inputs=[], perturbed=False)
  (/45): BoundParams(name=/45, inputs=[], perturbed=False)
  (/46): BoundParams(name=/46, inputs=[], perturbed=False)
  (/47): BoundParams(name=/47, inputs=[], perturbed=False)
  (/48): BoundParams(name=/48, inputs=[], perturbed=False)
  (/49): BoundParams(name=/49, inputs=[], perturbed=False)
  (/50): BoundParams(name=/50, inputs=[], perturbed=False)
  (/51): BoundParams(name=/51, inputs=[], perturbed=False)
  (/52): BoundParams(name=/52, inputs=[], perturbed=False)
  (/53): BoundParams(name=/53, inputs=[], perturbed=False)
  (/54): BoundParams(name=/54, inputs=[], perturbed=False)
  (/55): BoundParams(name=/55, inputs=[], perturbed=False)
  (/56): BoundParams(name=/56, inputs=[], perturbed=False)
  (/57): BoundConstant(name=/57, value=1)
  (/58): BoundConstant(name=/58, value=0)
  (/59): BoundConstant(name=/59, value=0)
  (/60): BoundConstant(name=/60, value=3)
  (/61): BoundAdd(name=/61, inputs=[/59, /60], perturbed=False)
  (/62): BoundUnsqueeze(name=/62, inputs=[/58], perturbed=False)
  (/63): BoundUnsqueeze(name=/63, inputs=[/61], perturbed=False)
  (/64): BoundUnsqueeze(name=/64, inputs=[/57], perturbed=False)
  (/65): BoundSlice(name=/65, inputs=[/0, /62, /63, /64], perturbed=False)
  (/66): BoundConstant(name=/66, value=2)
  (/67): BoundConstant(name=/67, value=0)
  (/68): BoundConstant(name=/68, value=0)
  (/69): BoundConstant(name=/69, value=7)
  (/70): BoundAdd(name=/70, inputs=[/68, /69], perturbed=False)
  (/71): BoundUnsqueeze(name=/71, inputs=[/67], perturbed=False)
  (/72): BoundUnsqueeze(name=/72, inputs=[/70], perturbed=False)
  (/73): BoundUnsqueeze(name=/73, inputs=[/66], perturbed=False)
  (/tensor): BoundSlice(name=/tensor, inputs=[/65, /71, /72, /73], perturbed=False)
  (/75): BoundSplit(name=/75, inputs=[/tensor], perturbed=False)
  (/76): BoundSplit(name=/76, inputs=[/tensor], perturbed=False)
  (/77): BoundConstant(name=/77, value=1)
  (/78): BoundConstant(name=/78, value=3)
  (/79): BoundConstant(name=/79, value=3)
  (/80): BoundConstant(name=/80, value=6)
  (/81): BoundAdd(name=/81, inputs=[/79, /80], perturbed=False)
  (/82): BoundUnsqueeze(name=/82, inputs=[/78], perturbed=False)
  (/83): BoundUnsqueeze(name=/83, inputs=[/81], perturbed=False)
  (/84): BoundUnsqueeze(name=/84, inputs=[/77], perturbed=False)
  (/85): BoundSlice(name=/85, inputs=[/0, /82, /83, /84], perturbed=False)
  (/86): BoundConstant(name=/86, value=2)
  (/87): BoundConstant(name=/87, value=0)
  (/88): BoundConstant(name=/88, value=0)
  (/89): BoundConstant(name=/89, value=14)
  (/90): BoundAdd(name=/90, inputs=[/88, /89], perturbed=False)
  (/91): BoundUnsqueeze(name=/91, inputs=[/87], perturbed=False)
  (/92): BoundUnsqueeze(name=/92, inputs=[/90], perturbed=False)
  (/93): BoundUnsqueeze(name=/93, inputs=[/86], perturbed=False)
  (/tensor.3): BoundSlice(name=/tensor.3, inputs=[/85, /91, /92, /93], perturbed=False)
  (/95): BoundSplit(name=/95, inputs=[/tensor.3], perturbed=False)
  (/96): BoundSplit(name=/96, inputs=[/tensor.3], perturbed=False)
  (/97): BoundConstant(name=/97, value=1)
  (/98): BoundConstant(name=/98, value=9)
  (/99): BoundConstant(name=/99, value=9)
  (/100): BoundConstant(name=/100, value=2)
  (/101): BoundAdd(name=/101, inputs=[/99, /100], perturbed=False)
  (/102): BoundUnsqueeze(name=/102, inputs=[/98], perturbed=False)
  (/103): BoundUnsqueeze(name=/103, inputs=[/101], perturbed=False)
  (/104): BoundUnsqueeze(name=/104, inputs=[/97], perturbed=False)
  (/105): BoundSlice(name=/105, inputs=[/0, /102, /103, /104], perturbed=False)
  (/106): BoundConstant(name=/106, value=2)
  (/107): BoundConstant(name=/107, value=0)
  (/108): BoundConstant(name=/108, value=0)
  (/109): BoundConstant(name=/109, value=7)
  (/110): BoundAdd(name=/110, inputs=[/108, /109], perturbed=False)
  (/111): BoundUnsqueeze(name=/111, inputs=[/107], perturbed=False)
  (/112): BoundUnsqueeze(name=/112, inputs=[/110], perturbed=False)
  (/113): BoundUnsqueeze(name=/113, inputs=[/106], perturbed=False)
  (/tensor.7): BoundSlice(name=/tensor.7, inputs=[/105, /111, /112, /113], perturbed=False)
  (/115): BoundSplit(name=/115, inputs=[/tensor.7], perturbed=False)
  (/116): BoundSplit(name=/116, inputs=[/tensor.7], perturbed=False)
  (/117): BoundTranspose(name=/117, inputs=[/41], perturbed=False)
  (/118): BoundMatMul(name=/118, inputs=[/75, /117], perturbed=False)
  (/input): BoundAdd(name=/input, inputs=[/42, /118], perturbed=False)
  (/120): BoundRelu(name=/120, inputs=[/input], perturbed=False)
  (/121): BoundTranspose(name=/121, inputs=[/43], perturbed=False)
  (/122): BoundMatMul(name=/122, inputs=[/120, /121], perturbed=False)
  (/input.3): BoundAdd(name=/input.3, inputs=[/44, /122], perturbed=False)
  (/124): BoundRelu(name=/124, inputs=[/input.3], perturbed=False)
  (/125): BoundMul(name=/125, inputs=[/124, /76], perturbed=False)
  (/126): BoundReduceSum(name=/126, inputs=[/125], perturbed=False)
  (/127): BoundReduceSum(name=/127, inputs=[/76], perturbed=False)
  (/129): BoundTranspose(name=/129, inputs=[/45], perturbed=False)
  (/130): BoundMatMul(name=/130, inputs=[/95, /129], perturbed=False)
  (/input.7): BoundAdd(name=/input.7, inputs=[/46, /130], perturbed=False)
  (/132): BoundRelu(name=/132, inputs=[/input.7], perturbed=False)
  (/133): BoundTranspose(name=/133, inputs=[/47], perturbed=False)
  (/134): BoundMatMul(name=/134, inputs=[/132, /133], perturbed=False)
  (/input.11): BoundAdd(name=/input.11, inputs=[/48, /134], perturbed=False)
  (/136): BoundRelu(name=/136, inputs=[/input.11], perturbed=False)
  (/137): BoundMul(name=/137, inputs=[/136, /96], perturbed=False)
  (/138): BoundReduceSum(name=/138, inputs=[/137], perturbed=False)
  (/139): BoundReduceSum(name=/139, inputs=[/96], perturbed=False)
  (/141): BoundTranspose(name=/141, inputs=[/49], perturbed=False)
  (/142): BoundMatMul(name=/142, inputs=[/115, /141], perturbed=False)
  (/input.15): BoundAdd(name=/input.15, inputs=[/50, /142], perturbed=False)
  (/144): BoundRelu(name=/144, inputs=[/input.15], perturbed=False)
  (/145): BoundTranspose(name=/145, inputs=[/51], perturbed=False)
  (/146): BoundMatMul(name=/146, inputs=[/144, /145], perturbed=False)
  (/input.19): BoundAdd(name=/input.19, inputs=[/52, /146], perturbed=False)
  (/148): BoundRelu(name=/148, inputs=[/input.19], perturbed=False)
  (/149): BoundMul(name=/149, inputs=[/148, /116], perturbed=False)
  (/150): BoundReduceSum(name=/150, inputs=[/149], perturbed=False)
  (/151): BoundReduceSum(name=/151, inputs=[/116], perturbed=False)
  (/153): BoundConcat(name=/153, inputs=[/128/mul, /140/mul, /152/mul], perturbed=False)
  (/input.23): BoundLinear(name=/input.23, inputs=[/153, /53, /54], perturbed=False)
  (/155): BoundRelu(name=/155, inputs=[/input.23], perturbed=False)
  (/156): BoundLinear(name=/156, inputs=[/155, /55, /56], perturbed=False)
  (/157): BoundSigmoid(name=/157, inputs=[/156], perturbed=False)
  (/128/reciprocal): BoundReciprocal(name=/128/reciprocal, inputs=[/127], perturbed=False)
  (/128/mul): BoundMul(name=/128/mul, inputs=[/126, /128/reciprocal], perturbed=False)
  (/140/reciprocal): BoundReciprocal(name=/140/reciprocal, inputs=[/139], perturbed=False)
  (/140/mul): BoundMul(name=/140/mul, inputs=[/138, /140/reciprocal], perturbed=False)
  (/152/reciprocal): BoundReciprocal(name=/152/reciprocal, inputs=[/151], perturbed=False)
  (/152/mul): BoundMul(name=/152/mul, inputs=[/150, /152/reciprocal], perturbed=False)
)
Model prediction is: tensor([0.74551517, 0.74551517, 0.66608024, 0.66608024, 0.69362700, 0.69362700,
        0.83512729, 0.83512729, 0.72079301, 0.72079301, 0.71335870, 0.71335870,
        0.67565584, 0.67565584, 0.73519558, 0.73519558, 0.76111305, 0.76111305,
        0.62238491, 0.62238491, 0.60555017, 0.60555017, 0.80330098, 0.80330098,
        0.83689475, 0.83689475, 0.85416615, 0.85416615, 0.81101608, 0.81101608,
        0.71613830, 0.71613830, 0.81751174, 0.81751174, 0.66546601, 0.66546601,
        0.65697676, 0.65697676, 0.65208822, 0.65208822, 0.72741246, 0.72741246,
        0.68148237, 0.68148237, 0.83022833, 0.83022833, 0.80119830, 0.80119830,
        0.75945979, 0.75945979, 0.74408108, 0.74408108, 0.74664521, 0.74664521,
        0.67313296, 0.67313296, 0.75216651, 0.75216651, 0.81729198, 0.81729198,
        0.86200196, 0.86200196, 0.67936569, 0.67936569, 0.64662480, 0.64662480,
        0.74678171, 0.74678171, 0.74522454, 0.74522454, 0.67748505, 0.67748505,
        0.72809595, 0.72809595, 0.70879912, 0.70879912, 0.55102438, 0.55102438,
        0.60579234, 0.60579234, 0.85991251, 0.85991251, 0.72038972, 0.72038972,
        0.75910187, 0.75910187, 0.83329773, 0.83329773, 0.74187529, 0.74187529,
        0.70399022, 0.70399022, 0.82898313, 0.82898313, 0.66001916, 0.66001916,
        0.72091872, 0.72091872, 0.70305151, 0.70305151, 0.61108935, 0.61108935,
        0.68888628, 0.68888628, 0.71718776, 0.71718776, 0.86489546, 0.86489546,
        0.67854351, 0.67854351, 0.75638092, 0.75638092, 0.73621082, 0.73621082,
        0.85120893, 0.85120893, 0.65466434, 0.65466434, 0.81868953, 0.81868953,
        0.72871977, 0.72871977, 0.86100894, 0.86100894, 0.70731139, 0.70731139,
        0.76417941, 0.76417941, 0.75674146, 0.75674146, 0.65190208, 0.65190208,
        0.74247837, 0.74247837, 0.69330788, 0.69330788, 0.68238491, 0.68238491,
        0.74246746, 0.74246746, 0.82880360, 0.82880360, 0.73447567, 0.73447567,
        0.75751305, 0.75751305, 0.75520390, 0.75520390, 0.71378118, 0.71378118,
        0.73345155, 0.73345155, 0.75858545, 0.75858545, 0.65037745, 0.65037745,
        0.73644710, 0.73644710, 0.68802291, 0.68802291, 0.75974798, 0.75974798,
        0.74215269, 0.74215269, 0.75766110, 0.75766110, 0.72306114, 0.72306114,
        0.68329835, 0.68329835, 0.66165876, 0.66165876, 0.67087436, 0.67087436,
        0.69120049, 0.69120049, 0.68338710, 0.68338710, 0.84929806, 0.84929806,
        0.67986065, 0.67986065, 0.69266111, 0.69266111, 0.73891866, 0.73891866,
        0.76299638, 0.76299638, 0.64274246, 0.64274246, 0.75066638, 0.75066638,
        0.66245288, 0.66245288, 0.84650135, 0.84650135, 0.67923182, 0.67923182,
        0.66408634, 0.66408634, 0.68346250, 0.68346250, 0.73824304, 0.73824304,
        0.71152872, 0.71152872, 0.72892153, 0.72892153, 0.84970278, 0.84970278,
        0.67649728, 0.67649728, 0.65850765, 0.65850765, 0.86579645, 0.86579645,
        0.71695316, 0.71695316, 0.72542095, 0.72542095, 0.75729537, 0.75729537,
        0.66146022, 0.66146022, 0.73881871, 0.73881871, 0.73630524, 0.73630524,
        0.81500804, 0.81500804, 0.63070560, 0.63070560, 0.76298887, 0.76298887,
        0.85615075, 0.85615075, 0.85918409, 0.85918409, 0.76217127, 0.76217127,
        0.74832928, 0.74832928, 0.62915045, 0.62915045, 0.73093635, 0.73093635,
        0.63538504, 0.63538504, 0.74583542, 0.74583542, 0.76055175, 0.76055175,
        0.72187740, 0.72187740, 0.84699750, 0.84699750, 0.77322930, 0.77322930,
        0.74895626, 0.74895626, 0.75655365, 0.75655365, 0.67242378, 0.67242378,
        0.72972208, 0.72972208, 0.86735028, 0.86735028, 0.73744994, 0.73744994,
        0.72747707, 0.72747707, 0.65284032, 0.65284032, 0.67285699, 0.67285699,
        0.71872038, 0.71872038, 0.67442930, 0.67442930, 0.84850025, 0.84850025,
        0.75453353, 0.75453353, 0.74214989, 0.74214989, 0.66742945, 0.66742945,
        0.71984357, 0.71984357, 0.66360915, 0.66360915, 0.74439591, 0.74439591,
        0.73724306, 0.73724306, 0.78931749, 0.78931749, 0.70117843, 0.70117843,
        0.84904486, 0.84904486, 0.74146032, 0.74146032, 0.63724560, 0.63724560,
        0.73089057, 0.73089057, 0.70540482, 0.70540482, 0.86416858, 0.86416858,
        0.67263228, 0.67263228, 0.73071945, 0.73071945, 0.72331429, 0.72331429,
        0.86080956, 0.86080956, 0.66285950, 0.66285950, 0.75706780, 0.75706780,
        0.72636861, 0.72636861, 0.65472913, 0.65472913, 0.75845337, 0.75845337,
        0.75030929, 0.75030929, 0.70076448, 0.70076448, 0.76302224, 0.76302224,
        0.79769725, 0.79769725, 0.76135075, 0.76135075, 0.86113578, 0.86113578,
        0.75987470, 0.75987470, 0.74555665, 0.74555665, 0.82058489, 0.82058489,
        0.85556889, 0.85556889, 0.86747855, 0.86747855, 0.78733754, 0.78733754,
        0.71580750, 0.71580750, 0.76116800, 0.76116800, 0.80118150, 0.80118150,
        0.75674325, 0.75674325, 0.75821549, 0.75821549, 0.66650110, 0.66650110,
        0.60512382, 0.60512382, 0.73753250, 0.73753250, 0.74376482, 0.74376482,
        0.70879275, 0.70879275, 0.68230957, 0.68230957, 0.74977010, 0.74977010,
        0.80100942, 0.80100942, 0.67310494, 0.67310494, 0.74376029, 0.74376029,
        0.72944796, 0.72944796, 0.64649516, 0.64649516, 0.82582545, 0.82582545,
        0.78253996, 0.78253996, 0.76302207, 0.76302207, 0.83633626, 0.83633626,
        0.84372878, 0.84372878, 0.71853197, 0.71853197, 0.75800925, 0.75800925,
        0.76320928, 0.76320928, 0.69831747, 0.69831747, 0.71989125, 0.71989125,
        0.67347103, 0.67347103, 0.73040265, 0.73040265, 0.84241992, 0.84241992,
        0.83024132, 0.83024132, 0.84737867, 0.84737867, 0.65457684, 0.65457684,
        0.66740161, 0.66740161, 0.70422310, 0.70422310, 0.76297861, 0.76297861,
        0.68086672, 0.68086672, 0.75664550, 0.75664550, 0.68973273, 0.68973273,
        0.75900763, 0.75900763, 0.74471426, 0.74471426, 0.66447186, 0.66447186,
        0.72025031, 0.72025031, 0.74290884, 0.74290884, 0.74905330, 0.74905330,
        0.74597460, 0.74597460, 0.76219434, 0.76219434, 0.84708464, 0.84708464,
        0.76311088, 0.76311088, 0.83521348, 0.83521348, 0.76643658, 0.76643658,
        0.65689647, 0.65689647, 0.82634646, 0.82634646, 0.75904709, 0.75904709,
        0.78513354, 0.78513354, 0.74516135, 0.74516135, 0.81395501, 0.81395501,
        0.67343014, 0.67343014, 0.81638855, 0.81638855, 0.67853612, 0.67853612,
        0.85916966, 0.85916966, 0.71210873, 0.71210873, 0.73860765, 0.73860765,
        0.66109282, 0.66109282, 0.81514132, 0.81514132, 0.71769840, 0.71769840,
        0.70443422, 0.70443422, 0.59342009, 0.59342009, 0.73001331, 0.73001331,
        0.85372370, 0.85372370, 0.67812836, 0.67812836, 0.86689138, 0.86689138,
        0.68361396, 0.68361396, 0.76025701, 0.76025701, 0.76296771, 0.76296771,
        0.68708241, 0.68708241, 0.87326556, 0.87326556, 0.75679076, 0.75679076,
        0.67379427, 0.67379427, 0.75119567, 0.75119567, 0.82208484, 0.82208484,
        0.75828886, 0.75828886, 0.75380534, 0.75380534, 0.63141572, 0.63141572,
        0.68584645, 0.68584645, 0.65522414, 0.65522414, 0.74699271, 0.74699271,
        0.80590111, 0.80590111, 0.62627274, 0.62627274, 0.74021930, 0.74021930,
        0.86727989, 0.86727989, 0.70142919, 0.70142919, 0.76203501, 0.76203501,
        0.85398817, 0.85398817, 0.70116174, 0.70116174, 0.85397094, 0.85397094,
        0.82413703, 0.82413703, 0.70069706, 0.70069706, 0.86771607, 0.86771607,
        0.86679000, 0.86679000, 0.68484485, 0.68484485, 0.72000015, 0.72000015,
        0.67082906, 0.67082906, 0.76275688, 0.76275688, 0.72201747, 0.72201747,
        0.71810943, 0.71810943, 0.62924939, 0.62924939, 0.76335001, 0.76335001,
        0.75617045, 0.75617045, 0.67944580, 0.67944580, 0.85377616, 0.85377616,
        0.71809214, 0.71809214, 0.76113796, 0.76113796, 0.73867321, 0.73867321,
        0.66842848, 0.66842848, 0.75147390, 0.75147390, 0.76228762, 0.76228762,
        0.73640931, 0.73640931, 0.85537738, 0.85537738, 0.73454678, 0.73454678,
        0.80034375, 0.80034375, 0.76067817, 0.76067817, 0.72013146, 0.72013146,
        0.87738591, 0.87738591, 0.74283087, 0.74283087, 0.68721801, 0.68721801,
        0.74765229, 0.74765229, 0.69986498, 0.69986498, 0.72627127, 0.72627127,
        0.76323920, 0.76323920, 0.70096636, 0.70096636, 0.75850111, 0.75850111,
        0.65580380, 0.65580380, 0.84789604, 0.84789604, 0.66671354, 0.66671354,
        0.67262113, 0.67262113, 0.67940563, 0.67940563, 0.68459076, 0.68459076,
        0.72951955, 0.72951955, 0.68133664, 0.68133664, 0.84971231, 0.84971231,
        0.68838423, 0.68838423, 0.80542022, 0.80542022, 0.83693802, 0.83693802,
        0.85184920, 0.85184920, 0.67622524, 0.67622524, 0.83024281, 0.83024281,
        0.37833291, 0.37833291, 0.73305988, 0.73305988, 0.72777307, 0.72777307,
        0.74596345, 0.74596345, 0.67316794, 0.67316794, 0.72109026, 0.72109026,
        0.65951365, 0.65951365, 0.63137788, 0.63137788, 0.81025654, 0.81025654,
        0.76298404, 0.76298404, 0.73875290, 0.73875290, 0.71050698, 0.71050698,
        0.67955685, 0.67955685, 0.66259068, 0.66259068, 0.75085080, 0.75085080,
        0.75487125, 0.75487125, 0.67927033, 0.67927033, 0.85740256, 0.85740256,
        0.69398743, 0.69398743, 0.73702747, 0.73702747, 0.63411433, 0.63411433,
        0.68376720, 0.68376720, 0.76326913, 0.76326913, 0.73881358, 0.73881358,
        0.71063042, 0.71063042, 0.75321567, 0.75321567, 0.66785163, 0.66785163,
        0.85706729, 0.85706729, 0.73498935, 0.73498935, 0.66728389, 0.66728389,
        0.85482419, 0.85482419, 0.68100005, 0.68100005, 0.83097351, 0.83097351,
        0.78049070, 0.78049070, 0.67166638, 0.67166638, 0.70018488, 0.70018488,
        0.70944166, 0.70944166, 0.67309803, 0.67309803, 0.71880376, 0.71880376,
        0.85496646, 0.85496646, 0.62541413, 0.62541413, 0.85157180, 0.85157180,
        0.73873860, 0.73873860, 0.66959882, 0.66959882, 0.67305475, 0.67305475,
        0.85567665, 0.85567665, 0.81111151, 0.81111151, 0.73653644, 0.73653644,
        0.73047632, 0.73047632, 0.73907447, 0.73907447, 0.75143039, 0.75143039,
        0.76464736, 0.76464736, 0.65733773, 0.65733773, 0.73415220, 0.73415220,
        0.73684174, 0.73684174, 0.71871269, 0.71871269, 0.76071680, 0.76071680,
        0.75146067, 0.75146067, 0.75875288, 0.75875288, 0.75547928, 0.75547928,
        0.85495377, 0.85495377, 0.67252123, 0.67252123, 0.72988147, 0.72988147,
        0.85224479, 0.85224479, 0.74243903, 0.74243903, 0.72784811, 0.72784811,
        0.74617177, 0.74617177, 0.76590699, 0.76590699, 0.62876898, 0.62876898,
        0.72599661, 0.72599661, 0.75861001, 0.75861001, 0.74348587, 0.74348587,
        0.63608664, 0.63608664, 0.83796537, 0.83796537, 0.71331578, 0.71331578,
        0.68977517, 0.68977517, 0.71962047, 0.71962047, 0.74536902, 0.74536902,
        0.69398874, 0.69398874, 0.67729151, 0.67729151, 0.72779745, 0.72779745,
        0.66988176, 0.66988176, 0.84207654, 0.84207654, 0.70236576, 0.70236576,
        0.67872602, 0.67872602, 0.76321656, 0.76321656, 0.62496781, 0.62496781,
        0.67587644, 0.67587644, 0.76224869, 0.76224869, 0.66124696, 0.66124696,
        0.83893764, 0.83893764, 0.67614496, 0.67614496, 0.70082158, 0.70082158,
        0.76302409, 0.76302409, 0.67924535, 0.67924535, 0.68238199, 0.68238199,
        0.68871319, 0.68871319, 0.75435865, 0.75435865, 0.71567291, 0.71567291,
        0.73621327, 0.73621327, 0.76465482, 0.76465482, 0.75420153, 0.75420153,
        0.67849606, 0.67849606, 0.64858019, 0.64858019, 0.72414351, 0.72414351,
        0.81998694, 0.81998694, 0.74627191, 0.74627191, 0.64380854, 0.64380854,
        0.66040516, 0.66040516, 0.75579661, 0.75579661, 0.68608540, 0.68608540,
        0.84774423, 0.84774423, 0.84968752, 0.84968752, 0.72739393, 0.72739393,
        0.66139668, 0.66139668, 0.68359202, 0.68359202, 0.75960690, 0.75960690,
        0.71817422, 0.71817422, 0.73908871, 0.73908871, 0.67823988, 0.67823988,
        0.73226601, 0.73226601, 0.73883867, 0.73883867, 0.84047234, 0.84047234,
        0.86536545, 0.86536545, 0.68993616, 0.68993616, 0.64211786, 0.64211786,
        0.64037716, 0.64037716, 0.75180376, 0.75180376, 0.75916719, 0.75916719,
        0.84739536, 0.84739536, 0.66237843, 0.66237843, 0.81603187, 0.81603187,
        0.74209458, 0.74209458, 0.62658811, 0.62658811, 0.95219529, 0.95219529,
        0.75960332, 0.75960332, 0.75487506, 0.75487506, 0.82634389, 0.82634389,
        0.83121890, 0.83121890, 0.84783626, 0.84783626, 0.65572363, 0.65572363,
        0.68336737, 0.68336737, 0.68024278, 0.68024278, 0.66981149, 0.66981149,
        0.68549246, 0.68549246, 0.66407710, 0.66407710, 0.73721689, 0.73721689,
        0.65092802, 0.65092802, 0.74877685, 0.74877685, 0.65768546, 0.65768546,
        0.67473847, 0.67473847, 0.66193932, 0.66193932, 0.64080876, 0.64080876,
        0.64476770, 0.64476770, 0.72369564, 0.72369564, 0.69681531, 0.69681531,
        0.71015841, 0.71015841, 0.68371272, 0.68371272, 0.68109143, 0.68109143,
        0.72845590, 0.72845590, 0.68805724, 0.68805724, 0.60815799, 0.60815799,
        0.66720790, 0.66720790, 0.70876515, 0.70876515, 0.75536436, 0.75536436,
        0.71115392, 0.71115392, 0.76574433, 0.76574433, 0.70912510, 0.70912510,
        0.74015099, 0.74015099, 0.64074224, 0.64074224, 0.72802854, 0.72802854,
        0.75311214, 0.75311214, 0.70263410, 0.70263410, 0.81225067, 0.81225067,
        0.83823967, 0.83823967, 0.85565579, 0.85565579], device='cuda:0')
Split layers:
  BoundAdd(name=/input, inputs=[/42, /118], perturbed=True): [(BoundRelu(name=/120, inputs=[/input], perturbed=True), 0)]
  BoundAdd(name=/input.3, inputs=[/44, /122], perturbed=True): [(BoundRelu(name=/124, inputs=[/input.3], perturbed=True), 0)]
  BoundRelu(name=/124, inputs=[/input.3], perturbed=True): [(BoundMul(name=/125, inputs=[/124, /76], perturbed=True), 0)]
  BoundSplit(name=/76, inputs=[/tensor], perturbed=True): [(BoundMul(name=/125, inputs=[/124, /76], perturbed=True), 1)]
  BoundAdd(name=/input.7, inputs=[/46, /130], perturbed=True): [(BoundRelu(name=/132, inputs=[/input.7], perturbed=True), 0)]
  BoundAdd(name=/input.11, inputs=[/48, /134], perturbed=True): [(BoundRelu(name=/136, inputs=[/input.11], perturbed=True), 0)]
  BoundRelu(name=/136, inputs=[/input.11], perturbed=True): [(BoundMul(name=/137, inputs=[/136, /96], perturbed=True), 0)]
  BoundSplit(name=/96, inputs=[/tensor.3], perturbed=True): [(BoundMul(name=/137, inputs=[/136, /96], perturbed=True), 1)]
  BoundAdd(name=/input.15, inputs=[/50, /142], perturbed=True): [(BoundRelu(name=/144, inputs=[/input.15], perturbed=True), 0)]
  BoundAdd(name=/input.19, inputs=[/52, /146], perturbed=True): [(BoundRelu(name=/148, inputs=[/input.19], perturbed=True), 0)]
  BoundRelu(name=/148, inputs=[/input.19], perturbed=True): [(BoundMul(name=/149, inputs=[/148, /116], perturbed=True), 0)]
  BoundSplit(name=/116, inputs=[/tensor.7], perturbed=True): [(BoundMul(name=/149, inputs=[/148, /116], perturbed=True), 1)]
  BoundLinear(name=/input.23, inputs=[/153, /53, /54], perturbed=True): [(BoundRelu(name=/155, inputs=[/input.23], perturbed=True), 0)]
  BoundLinear(name=/156, inputs=[/155, /55, /56], perturbed=True): [(BoundSigmoid(name=/157, inputs=[/156], perturbed=True), 0)]
  BoundReduceSum(name=/127, inputs=[/76], perturbed=True): [(BoundReciprocal(name=/128/reciprocal, inputs=[/127], perturbed=True), 0)]
  BoundReduceSum(name=/126, inputs=[/125], perturbed=True): [(BoundMul(name=/128/mul, inputs=[/126, /128/reciprocal], perturbed=True), 0)]
  BoundReciprocal(name=/128/reciprocal, inputs=[/127], perturbed=True): [(BoundMul(name=/128/mul, inputs=[/126, /128/reciprocal], perturbed=True), 1)]
  BoundReduceSum(name=/139, inputs=[/96], perturbed=True): [(BoundReciprocal(name=/140/reciprocal, inputs=[/139], perturbed=True), 0)]
  BoundReduceSum(name=/138, inputs=[/137], perturbed=True): [(BoundMul(name=/140/mul, inputs=[/138, /140/reciprocal], perturbed=True), 0)]
  BoundReciprocal(name=/140/reciprocal, inputs=[/139], perturbed=True): [(BoundMul(name=/140/mul, inputs=[/138, /140/reciprocal], perturbed=True), 1)]
  BoundReduceSum(name=/151, inputs=[/116], perturbed=True): [(BoundReciprocal(name=/152/reciprocal, inputs=[/151], perturbed=True), 0)]
  BoundReduceSum(name=/150, inputs=[/149], perturbed=True): [(BoundMul(name=/152/mul, inputs=[/150, /152/reciprocal], perturbed=True), 0)]
  BoundReciprocal(name=/152/reciprocal, inputs=[/151], perturbed=True): [(BoundMul(name=/152/mul, inputs=[/150, /152/reciprocal], perturbed=True), 1)]
Nonlinear functions:
   BoundRelu(name=/120, inputs=[/input], perturbed=True)
   BoundRelu(name=/124, inputs=[/input.3], perturbed=True)
   BoundMul(name=/125, inputs=[/124, /76], perturbed=True)
   BoundRelu(name=/132, inputs=[/input.7], perturbed=True)
   BoundRelu(name=/136, inputs=[/input.11], perturbed=True)
   BoundMul(name=/137, inputs=[/136, /96], perturbed=True)
   BoundRelu(name=/144, inputs=[/input.15], perturbed=True)
   BoundRelu(name=/148, inputs=[/input.19], perturbed=True)
   BoundMul(name=/149, inputs=[/148, /116], perturbed=True)
   BoundRelu(name=/155, inputs=[/input.23], perturbed=True)
   BoundSigmoid(name=/157, inputs=[/156], perturbed=True)
   BoundReciprocal(name=/128/reciprocal, inputs=[/127], perturbed=True)
   BoundMul(name=/128/mul, inputs=[/126, /128/reciprocal], perturbed=True)
   BoundReciprocal(name=/140/reciprocal, inputs=[/139], perturbed=True)
   BoundMul(name=/140/mul, inputs=[/138, /140/reciprocal], perturbed=True)
   BoundReciprocal(name=/152/reciprocal, inputs=[/151], perturbed=True)
   BoundMul(name=/152/mul, inputs=[/150, /152/reciprocal], perturbed=True)
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.1024119183421135
initial forward+backward bounds: tensor([[ 0.73456085],
        [-0.75268525],
        [ 0.65365642],
        [-0.68034112],
        [ 0.68268144],
        [-0.70560211],
        [ 0.80201769],
        [-0.85795659],
        [ 0.71927285],
        [-0.72238493],
        [ 0.69774675],
        [-0.73320025],
        [ 0.63507628],
        [-0.72253764],
        [ 0.72054833],
        [-0.75981742],
        [ 0.75977296],
        [-0.76217121],
        [ 0.56280720],
        [-0.65458852],
        [ 0.53693497],
        [-0.69868326],
        [ 0.78345388],
        [-0.82198006],
        [ 0.57627720],
        [-1.13225055],
        [ 0.84669274],
        [-0.86079717],
        [ 0.40388596],
        [-1.21463716],
        [ 0.70986819],
        [-0.72341132],
        [ 0.80218774],
        [-0.83210450],
        [ 0.65215170],
        [-0.68127596],
        [ 0.57917738],
        [-0.72976059],
        [ 0.46887875],
        [-0.81886142],
        [ 0.71256876],
        [-0.74675626],
        [ 0.62265444],
        [-0.75163317],
        [ 0.82900107],
        [-0.83112258],
        [ 0.61781418],
        [-0.98455673],
        [ 0.34893700],
        [-0.91819322],
        [ 0.73093343],
        [-0.75222123],
        [ 0.74054301],
        [-0.75190276],
        [ 0.66695100],
        [-0.67875153],
        [ 0.72357941],
        [-0.77279305],
        [ 0.80231607],
        [-0.83127445],
        [ 0.86020440],
        [-0.86377203],
        [ 0.64075530],
        [-0.72495192],
        [ 0.60732961],
        [-0.69250745],
        [ 0.73814112],
        [-0.75388867],
        [ 0.72886461],
        [-0.76417655],
        [ 0.64421695],
        [-0.71765226],
        [ 0.71751916],
        [-0.74016696],
        [ 0.69560808],
        [-0.72280967],
        [ 0.46248910],
        [-0.60906142],
        [ 0.60311574],
        [-0.60854656],
        [ 0.82674396],
        [-0.88240176],
        [ 0.71846873],
        [-0.72238666],
        [ 0.75538731],
        [-0.76226598],
        [ 0.02404722],
        [-1.72993219],
        [ 0.64006990],
        [-0.76864433],
        [ 0.44173563],
        [-0.94102347],
        [ 0.82405734],
        [-0.83281016],
        [ 0.65807271],
        [-0.66196305],
        [ 0.71725911],
        [-0.72459084],
        [ 0.69507229],
        [-0.71070427],
        [ 0.26944259],
        [-1.01990414],
        [ 0.62483764],
        [-0.77124715],
        [ 0.71030152],
        [-0.72357714],
        [ 0.85812736],
        [-0.87173253],
        [ 0.62086654],
        [-0.73558575],
        [ 0.75379074],
        [-0.75811863],
        [ 0.71284449],
        [-0.75551438],
        [ 0.69334364],
        [-0.93215138],
        [ 0.65320629],
        [-0.65609896],
        [ 0.07352170],
        [-1.25396395],
        [ 0.72743618],
        [-0.73005891],
        [ 0.78672880],
        [-0.89847082],
        [ 0.66412288],
        [-0.76808131],
        [ 0.74437922],
        [-0.78615481],
        [ 0.71949846],
        [-0.77022821],
        [ 0.58546376],
        [-0.70773458],
        [ 0.73821592],
        [-0.74669939],
        [ 0.68034267],
        [-0.70735490],
        [ 0.64032102],
        [-0.73263121],
        [ 0.73746085],
        [-0.74691522],
        [ 0.73999393],
        [-0.87932718],
        [ 0.71665221],
        [-0.76493567],
        [ 0.72542274],
        [-0.77218539],
        [ 0.59746987],
        [-0.81578326],
        [ 0.69593650],
        [-0.73512077],
        [ 0.72531009],
        [-0.74008965],
        [ 0.75563449],
        [-0.76192075],
        [ 0.45606229],
        [-0.81124586],
        [ 0.72579086],
        [-0.75173897],
        [ 0.68384898],
        [-0.69205642],
        [ 0.59150141],
        [-0.86566359],
        [ 0.74060023],
        [-0.74362302],
        [ 0.75485349],
        [-0.76030105],
        [ 0.71218407],
        [-0.73447722],
        [ 0.62047458],
        [-0.76149106],
        [ 0.51961583],
        [-0.84774286],
        [ 0.63329124],
        [-0.69788992],
        [ 0.62044662],
        [-0.78717232],
        [ 0.60659242],
        [-0.75375491],
        [ 0.53222603],
        [-1.22479367],
        [ 0.67111564],
        [-0.68943566],
        [ 0.68068439],
        [-0.70566773],
        [ 0.72104388],
        [-0.74852097],
        [ 0.63603944],
        [-0.84765381],
        [ 0.64118361],
        [-0.64427942],
        [ 0.72742784],
        [-0.76689982],
        [ 0.65282702],
        [-0.67328733],
        [ 0.62369913],
        [-1.14924240],
        [ 0.60758245],
        [-0.76759726],
        [ 0.53716159],
        [-0.84085959],
        [ 0.14749487],
        [-1.31701684],
        [ 0.73804206],
        [-0.73844534],
        [ 0.68090564],
        [-0.75145942],
        [ 0.71397567],
        [-0.74843132],
        [ 0.74622709],
        [-0.90807921],
        [ 0.64802915],
        [-0.70980251],
        [ 0.65104115],
        [-0.66497403],
        [ 0.76767844],
        [-0.90605313],
        [ 0.71030539],
        [-0.72286171],
        [ 0.41583744],
        [-0.87190276],
        [ 0.75619465],
        [-0.75836015],
        [ 0.63994753],
        [-0.68278199],
        [ 0.73830003],
        [-0.73933315],
        [ 0.72622186],
        [-0.75173426],
        [ 0.80587947],
        [-0.82429588],
        [ 0.62438703],
        [-0.63786799],
        [ 0.63135123],
        [-0.84980696],
        [ 0.83692360],
        [-0.87280309],
        [ 0.84670454],
        [-0.87132913],
        [ 0.70596796],
        [-0.80307388],
        [ 0.74164712],
        [-0.75500190],
        [ 0.13014132],
        [-1.24930620],
        [ 0.72731417],
        [-0.73452598],
        [ 0.53068852],
        [-0.71428841],
        [ 0.74062866],
        [-0.74991339],
        [ 0.61853623],
        [-0.87496233],
        [ 0.71918976],
        [-0.72458267],
        [ 0.05423515],
        [-1.35882926],
        [ 0.73196340],
        [-0.81327379],
        [ 0.73758125],
        [-0.76216745],
        [ 0.71513021],
        [-0.77067941],
        [ 0.62426513],
        [-0.72441709],
        [ 0.72074783],
        [-0.73948044],
        [ 0.84928745],
        [-0.87725753],
        [ 0.73488683],
        [-0.73986113],
        [ 0.71165043],
        [-0.74853426],
        [ 0.59412909],
        [-0.70656687],
        [ 0.50417238],
        [-0.83868474],
        [ 0.71435523],
        [-0.72367454],
        [ 0.62592494],
        [-0.70555437],
        [ 0.38157648],
        [-1.23532689],
        [ 0.74704015],
        [-0.76367569],
        [ 0.73722184],
        [-0.74673384],
        [ 0.64338034],
        [-0.69629633],
        [ 0.67842692],
        [-0.77407616],
        [ 0.65268397],
        [-0.67635459],
        [ 0.72036088],
        [-0.75645715],
        [ 0.73432243],
        [-0.73972178],
        [ 0.71481752],
        [-0.83192474],
        [ 0.66500217],
        [-0.72072375],
        [ 0.84687507],
        [-0.85164791],
        [ 0.73398757],
        [-0.74785000],
        [ 0.55519605],
        [-0.67281342],
        [ 0.71061295],
        [-0.76126975],
        [ 0.68040097],
        [-0.73091823],
        [ 0.85671884],
        [-0.87217444],
        [ 0.61626142],
        [-0.71169090],
        [ 0.71065140],
        [-0.76038867],
        [ 0.70422065],
        [-0.74690121],
        [ 0.83296466],
        [-0.88145947],
        [ 0.50347751],
        [-0.88235259],
        [ 0.74139512],
        [-0.76478183],
        [ 0.72107142],
        [-0.73177969],
        [ 0.41953701],
        [-0.91157919],
        [ 0.71599084],
        [-0.77945048],
        [ 0.74852037],
        [-0.75214344],
        [ 0.69633532],
        [-0.70524633],
        [ 0.65595162],
        [-0.83766377],
        [ 0.60059816],
        [-0.96212071],
        [ 0.75938821],
        [-0.76294613],
        [ 0.83071876],
        [-0.88143468],
        [ 0.75480211],
        [-0.76364630],
        [ 0.73763204],
        [-0.75128400],
        [ 0.54308212],
        [-1.07250786],
        [ 0.85205925],
        [-0.86002010],
        [ 0.86532450],
        [-0.86905193],
        [ 0.64649010],
        [-0.85612738],
        [ 0.70918435],
        [-0.72341746],
        [ 0.75306374],
        [-0.76660091],
        [ 0.57516211],
        [-1.04328632],
        [ 0.75620848],
        [-0.75728083],
        [ 0.70623666],
        [-0.78022259],
        [ 0.65220499],
        [-0.68065017],
        [ 0.56045246],
        [-0.64842939],
        [ 0.20244408],
        [-1.23212016],
        [ 0.72918117],
        [-0.75382876],
        [ 0.69560820],
        [-0.72279084],
        [ 0.63150239],
        [-0.74452543],
        [ 0.71897244],
        [-0.76729846],
        [ 0.78212941],
        [-0.81282872],
        [ 0.50081480],
        [-0.84298384],
        [ 0.72084588],
        [-0.75691301],
        [ 0.72075140],
        [-0.73863965],
        [ 0.49441263],
        [-0.78823280],
        [ 0.07939449],
        [-1.31176269],
        [ 0.30371451],
        [-1.48429334],
        [ 0.39223808],
        [-0.94667107],
        [ 0.81115234],
        [-0.85662508],
        [ 0.84280699],
        [-0.84481728],
        [ 0.68448305],
        [-0.76771861],
        [ 0.75382930],
        [-0.76216054],
        [ 0.60859036],
        [-0.92456758],
        [ 0.17834345],
        [-1.03894854],
        [ 0.71868408],
        [-0.72147810],
        [ 0.60966265],
        [-0.71257901],
        [ 0.64620852],
        [-0.75551534],
        [ 0.68288422],
        [-0.91226590],
        [ 0.38557673],
        [-1.18831074],
        [ 0.04027651],
        [-1.36889482],
        [ 0.65320611],
        [-0.65592420],
        [ 0.64329177],
        [-0.69629979],
        [ 0.67797863],
        [-0.73004436],
        [ 0.63227475],
        [-0.84872723],
        [ 0.58836222],
        [-0.80241895],
        [ 0.72128135],
        [-0.76946908],
        [ 0.61814433],
        [-0.78524226],
        [ 0.75017345],
        [-0.76558006],
        [ 0.63563591],
        [-0.77168167],
        [ 0.49295759],
        [-0.90652245],
        [ 0.70722431],
        [-0.73455977],
        [ 0.70983052],
        [-0.75902849],
        [ 0.62775218],
        [-0.77877975],
        [ 0.70837027],
        [-0.76214719],
        [ 0.70612746],
        [-0.80292463],
        [-0.07831518],
        [-1.46742773],
        [ 0.59240210],
        [-0.92730254],
        [ 0.16372673],
        [-1.34476817],
        [ 0.76581883],
        [-0.76702189],
        [ 0.63747138],
        [-0.67391616],
        [ 0.62257713],
        [-1.07457924],
        [ 0.75221580],
        [-0.76403308],
        [ 0.67354184],
        [-0.87541133],
        [ 0.74286443],
        [-0.74747765],
        [ 0.75371301],
        [-0.86183155],
        [ 0.62742025],
        [-0.70484227],
        [ 0.26113915],
        [-1.34197509],
        [ 0.64717638],
        [-0.71728832],
        [ 0.81622291],
        [-0.88891536],
        [ 0.67567360],
        [-0.76645482],
        [ 0.73736376],
        [-0.73986888],
        [ 0.64622027],
        [-0.67666918],
        [ 0.44420764],
        [-1.19658041],
        [ 0.70517838],
        [-0.73007715],
        [ 0.69596207],
        [-0.71236420],
        [ 0.55619770],
        [-0.63843477],
        [ 0.71690208],
        [-0.74640071],
        [ 0.84452325],
        [-0.85982859],
        [ 0.64412045],
        [-0.72018778],
        [ 0.86553961],
        [-0.86832035],
        [ 0.61448634],
        [-0.77211744],
        [ 0.75395054],
        [-0.76493526],
        [ 0.61087912],
        [-0.91368639],
        [ 0.51638055],
        [-0.88719642],
        [ 0.36103722],
        [-1.21827519],
        [ 0.72121376],
        [-0.77009928],
        [ 0.45618814],
        [-0.90375596],
        [ 0.73571402],
        [-0.76469803],
        [ 0.10084902],
        [-1.36937058],
        [ 0.74399674],
        [-0.76674932],
        [ 0.15614894],
        [-1.02156663],
        [ 0.62272912],
        [-0.64009249],
        [ 0.68473691],
        [-0.68702364],
        [ 0.65354502],
        [-0.65705496],
        [ 0.71899295],
        [-0.76320738],
        [ 0.76889855],
        [-0.83269083],
        [ 0.16815324],
        [-1.14256549],
        [ 0.73437822],
        [-0.74612749],
        [ 0.84691334],
        [-0.88076913],
        [ 0.67193717],
        [-0.71834272],
        [ 0.75853872],
        [-0.76516742],
        [ 0.84496576],
        [-0.86091006],
        [ 0.68375051],
        [-0.71207553],
        [ 0.84478986],
        [-0.86092281],
        [ 0.21608990],
        [-1.19658601],
        [ 0.69993627],
        [-0.70145744],
        [ 0.86634123],
        [-0.86900109],
        [ 0.85480177],
        [-0.87603700],
        [ 0.68074632],
        [-0.68921244],
        [ 0.71589261],
        [-0.72460026],
        [ 0.63804108],
        [-0.70482159],
        [ 0.73475039],
        [-0.79496223],
        [ 0.71527094],
        [-0.72890395],
        [ 0.69049859],
        [-0.75531262],
        [ 0.12912013],
        [-1.25622010],
        [ 0.57180691],
        [-0.94275635],
        [ 0.73100787],
        [-0.76540595],
        [ 0.63116843],
        [-0.73739123],
        [ 0.84699339],
        [-0.85862702],
        [ 0.71463978],
        [-0.72209507],
        [ 0.75274152],
        [-0.76661688],
        [ 0.73803920],
        [-0.73930752],
        [ 0.64781624],
        [-0.69350988],
        [ 0.72997028],
        [-0.76839131],
        [ 0.43525639],
        [-0.93855512],
        [ 0.73253763],
        [-0.74008602],
        [ 0.64629835],
        [-0.94868565],
        [ 0.71665001],
        [-0.76527882],
        [ 0.27008516],
        [-1.21636522],
        [ 0.76014644],
        [-0.76113588],
        [ 0.71833485],
        [-0.72208083],
        [ 0.59732538],
        [-1.19134212],
        [ 0.74178535],
        [-0.74387127],
        [ 0.62266994],
        [-0.76981807],
        [ 0.73056889],
        [-0.76039326],
        [ 0.69568473],
        [-0.70691437],
        [ 0.65024370],
        [-0.75687802],
        [ 0.49614501],
        [-0.94588667],
        [ 0.70055497],
        [-0.70137793],
        [ 0.71781397],
        [-0.77871770],
        [ 0.64379728],
        [-0.66516662],
        [-0.08230966],
        [-1.48382008],
        [ 0.65501159],
        [-0.68032056],
        [ 0.50091577],
        [-0.83978152],
        [ 0.58905369],
        [-0.75945735],
        [ 0.61612189],
        [-0.77369970],
        [ 0.62856454],
        [-0.80803329],
        [ 0.63780260],
        [-0.73293614],
        [ 0.74618495],
        [-0.90841001],
        [ 0.65854049],
        [-0.72193313],
        [ 0.69679374],
        [-0.87223643],
        [ 0.57732785],
        [-1.13188910],
        [ 0.74407995],
        [-0.90890044],
        [ 0.65220535],
        [-0.69981223],
        [ 0.71725190],
        [-0.91535842],
        [ 0.24964958],
        [-0.85863376],
        [ 0.72717541],
        [-0.73963630],
        [ 0.70339698],
        [-0.76573551],
        [ 0.74106395],
        [-0.74990582],
        [ 0.52806956],
        [-0.81166887],
        [ 0.71884680],
        [-0.72333890],
        [ 0.52593440],
        [-0.81522870],
        [ 0.62511277],
        [-0.63786083],
        [ 0.79876935],
        [-0.81760818],
        [ 0.73989820],
        [-0.78720808],
        [ 0.73811644],
        [-0.73937899],
        [ 0.68706483],
        [-0.74273074],
        [ 0.64135957],
        [-0.72490162],
        [ 0.54848391],
        [-0.81254989],
        [ 0.73492903],
        [-0.76408374],
        [ 0.72121984],
        [-0.77567834],
        [ 0.64089894],
        [-0.72457147],
        [ 0.67550051],
        [-0.94630718],
        [ 0.64392382],
        [-0.75136161],
        [ 0.73519802],
        [-0.73873329],
        [ 0.61924636],
        [-0.64876646],
        [ 0.64928907],
        [-0.71731567],
        [ 0.67650384],
        [-0.82477647],
        [ 0.72059828],
        [-0.75953448],
        [ 0.66905886],
        [-0.77202547],
        [ 0.61676908],
        [-0.79987377],
        [ 0.64928961],
        [-0.68616766],
        [ 0.83596939],
        [-0.87394899],
        [ 0.72009212],
        [-0.75983429],
        [ 0.64524722],
        [-0.69365257],
        [ 0.61501759],
        [-1.18181789],
        [ 0.64529085],
        [-0.72323805],
        [ 0.81659180],
        [-0.84433371],
        [ 0.74887580],
        [-0.80154121],
        [ 0.64928877],
        [-0.69367898],
        [ 0.67524832],
        [-0.72567755],
        [ 0.70848441],
        [-0.71040511],
        [ 0.64928865],
        [-0.69649166],
        [ 0.68739361],
        [-0.76314789],
        [ 0.85190505],
        [-0.85737365],
        [ 0.35472530],
        [-0.75139290],
        [ 0.74833387],
        [-0.90641207],
        [ 0.64049816],
        [-0.76337004],
        [ 0.66708976],
        [-0.67220485],
        [ 0.64094144],
        [-0.69896823],
        [ 0.25696766],
        [-1.25434744],
        [ 0.80716193],
        [-0.81501555],
        [ 0.72598785],
        [-0.75173455],
        [ 0.71689481],
        [-0.74799585],
        [ 0.64033955],
        [-0.76432765],
        [ 0.73535329],
        [-0.76562816],
        [ 0.69824886],
        [-0.81837237],
        [ 0.55631763],
        [-0.76941967],
        [ 0.72205120],
        [-0.74799943],
        [ 0.72249895],
        [-0.74663001],
        [ 0.71433967],
        [-0.72367448],
        [ 0.76001716],
        [-0.76132363],
        [ 0.73558712],
        [-0.76561224],
        [ 0.71287382],
        [-0.77943760],
        [ 0.72963899],
        [-0.77557260],
        [ 0.85309738],
        [-0.85794437],
        [ 0.51492095],
        [-0.82309234],
        [ 0.71661556],
        [-0.74640870],
        [ 0.76458788],
        [-0.89565176],
        [ 0.73723412],
        [-0.74774319],
        [ 0.70296240],
        [-0.76616108],
        [ 0.73804456],
        [-0.75248736],
        [ 0.68795818],
        [-0.81518358],
        [ 0.13624145],
        [-1.22502029],
        [ 0.70531392],
        [-0.75428802],
        [ 0.75569099],
        [-0.76191449],
        [ 0.74178439],
        [-0.74512100],
        [ 0.40305990],
        [-0.80960739],
        [ 0.68923116],
        [-0.90836823],
        [ 0.69478148],
        [-0.73515463],
        [ 0.65196466],
        [-0.73406315],
        [ 0.51246655],
        [-0.80057967],
        [ 0.73763728],
        [-0.75085020],
        [ 0.67354590],
        [-0.71582645],
        [ 0.60940164],
        [-0.75761861],
        [ 0.71786296],
        [-0.73869860],
        [ 0.58165663],
        [-0.73622316],
        [ 0.05114415],
        [-1.47962785],
        [ 0.66819561],
        [-0.73798090],
        [ 0.59764123],
        [-0.78040594],
        [ 0.61049277],
        [-0.92435390],
        [ 0.58926588],
        [-0.63972324],
        [ 0.55682218],
        [-0.78186190],
        [ 0.76163089],
        [-0.76286602],
        [ 0.65094882],
        [-0.67254901],
        [-0.31718752],
        [-1.77970958],
        [ 0.61383474],
        [-0.73045969],
        [ 0.67657548],
        [-0.72513825],
        [ 0.65639621],
        [-0.83744156],
        [ 0.62849879],
        [-0.74006814],
        [ 0.63183391],
        [-0.74449193],
        [ 0.68511653],
        [-0.69227636],
        [ 0.75424159],
        [-0.75447673],
        [ 0.70986885],
        [-0.72214115],
        [ 0.71845788],
        [-0.76473325],
        [ 0.70108360],
        [-0.81562817],
        [ 0.74675745],
        [-0.76183254],
        [ 0.66802633],
        [-0.69669706],
        [ 0.57798797],
        [-0.72174913],
        [ 0.70601571],
        [-0.74684119],
        [ 0.22563735],
        [-1.26424754],
        [ 0.73796117],
        [-0.75277972],
        [ 0.58961999],
        [-0.69732994],
        [ 0.64625448],
        [-0.67646986],
        [ 0.75254869],
        [-0.75922906],
        [ 0.65140188],
        [-0.76120657],
        [ 0.79374069],
        [-0.88803428],
        [ 0.11760526],
        [-1.33773685],
        [ 0.70258248],
        [-0.76579618],
        [ 0.51320440],
        [-0.85236531],
        [ 0.61450917],
        [-0.77189261],
        [ 0.75484133],
        [-0.76392198],
        [ 0.71462506],
        [-0.72232443],
        [ 0.72233021],
        [-0.74848056],
        [ 0.60504091],
        [-0.76754749],
        [ 0.72057241],
        [-0.74814945],
        [ 0.64334005],
        [-0.76314217],
        [ 0.82752544],
        [-0.84889406],
        [ 0.84513783],
        [-0.88047010],
        [ 0.61661530],
        [-0.78814292],
        [ 0.58880931],
        [-0.69156432],
        [ 0.55474639],
        [-0.67928606],
        [ 0.46744943],
        [-0.86043525],
        [ 0.75558627],
        [-0.76226234],
        [ 0.66209549],
        [-1.10663462],
        [ 0.50622064],
        [-0.87277442],
        [ 0.80071157],
        [-0.83127892],
        [ 0.73887956],
        [-0.74518788],
        [ 0.58051854],
        [-0.65232956],
        [ 0.87281442],
        [-0.96700758],
        [ 0.75482821],
        [-0.76392233],
        [ 0.74435276],
        [-0.76150298],
        [ 0.82177526],
        [-0.82977211],
        [ 0.46373883],
        [-1.35178125],
        [ 0.80931741],
        [-0.88012987],
        [ 0.57401860],
        [-0.73094267],
        [ 0.63460255],
        [-0.74355000],
        [ 0.64376193],
        [-0.72401875],
        [ 0.56807929],
        [-0.74535167],
        [ 0.61520821],
        [-0.78254378],
        [ 0.49143386],
        [-0.90834981],
        [ 0.73440719],
        [-0.73966420],
        [ 0.45392016],
        [-0.81928146],
        [ 0.73796016],
        [-0.75559103],
        [ 0.64340711],
        [-0.66803861],
        [ 0.61916792],
        [-0.73989993],
        [ 0.53286690],
        [-0.82964587],
        [ 0.50645721],
        [-0.75380701],
        [ 0.62650448],
        [-0.66397536],
        [ 0.70504785],
        [-0.74687284],
        [ 0.61441553],
        [-0.73240513],
        [ 0.69529092],
        [-0.72579902],
        [ 0.61438388],
        [-0.77312857],
        [ 0.64527345],
        [-0.72359699],
        [ 0.72727859],
        [-0.72966635],
        [ 0.64955431],
        [-0.72536045],
        [-0.10809382],
        [-1.19629800],
        [ 0.54686958],
        [-0.74178791],
        [ 0.70090717],
        [-0.71495450],
        [ 0.72794902],
        [-0.76766270],
        [ 0.67284322],
        [-0.76679403],
        [ 0.75921351],
        [-0.77071214],
        [ 0.69472927],
        [-0.72378808],
        [ 0.63937449],
        [-0.76619709],
        [ 0.50835520],
        [-0.75040311],
        [ 0.28290775],
        [-0.87048972],
        [ 0.45467666],
        [-0.86689150],
        [ 0.57557631],
        [-0.74043286],
        [ 0.75413322],
        [-0.85817188],
        [ 0.82361150],
        [-0.85177702],
        [ 0.25617421],
        [-1.25236285]], device='cuda:0')
Worst class: (+ rhs) -1.7797095775604248
Iteration 1
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.06769576668739319
Worst bound: tensor([-0.31337756], device='cuda:0')
Total time: 0.0550  pickout: 0.0002 decision: 0.0009  bounding: 0.0534 add_domain: 0.0005
length of domains: 842
100 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 2.479588508605957

Iteration 2
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04460183158516884
Worst bound: tensor([-0.10247916], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 828
200 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 2.5314011573791504

Iteration 3
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04083177447319031
Worst bound: tensor([-0.10646015], device='cuda:0')
Total time: 0.0517  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 816
300 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 2.5833029747009277

Iteration 4
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03716737776994705
Worst bound: tensor([-0.06219113], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 800
400 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 2.635023355484009

Iteration 5
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.038442935794591904
Worst bound: tensor([-0.05915403], device='cuda:0')
Total time: 0.0517  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 793
500 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 2.6869559288024902

Iteration 6
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.027281150221824646
Worst bound: tensor([-0.02150500], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0004
length of domains: 772
600 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 2.7387778759002686

Iteration 7
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.032936155796051025
Worst bound: tensor([-0.64827579], device='cuda:0')
Total time: 0.0518  pickout: 0.0002 decision: 0.0008  bounding: 0.0504 add_domain: 0.0005
length of domains: 754
700 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 2.790788412094116

Iteration 8
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.06599332392215729
Worst bound: tensor([-0.43801749], device='cuda:0')
Total time: 0.3234  pickout: 0.0002 decision: 0.0008  bounding: 0.3220 add_domain: 0.0005
length of domains: 739
800 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 3.1144137382507324

Iteration 9
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.07131901383399963
Worst bound: tensor([-0.04461509], device='cuda:0')
Total time: 0.0460  pickout: 0.0002 decision: 0.0008  bounding: 0.0445 add_domain: 0.0005
length of domains: 722
900 branch and bound domains visited
Current (lb-rhs): -1.0319797992706299
Cumulative time: 3.1605772972106934

Iteration 10
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.09269998967647552
Worst bound: tensor([-0.31170571], device='cuda:0')
Total time: 0.0459  pickout: 0.0002 decision: 0.0008  bounding: 0.0445 add_domain: 0.0005
length of domains: 715
1000 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.206707000732422

Iteration 11
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.07253217697143555
Worst bound: tensor([-0.05877024], device='cuda:0')
Total time: 0.0458  pickout: 0.0002 decision: 0.0008  bounding: 0.0444 add_domain: 0.0005
length of domains: 699
1100 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.2527482509613037

Iteration 12
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03961721435189247
Worst bound: tensor([-0.08131474], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 681
1200 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.304537296295166

Iteration 13
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.034808628261089325
Worst bound: tensor([-0.11609083], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 662
1300 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.3563156127929688

Iteration 14
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03220142796635628
Worst bound: tensor([-0.03486538], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 644
1400 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.4081778526306152

Iteration 15
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.029161551967263222
Worst bound: tensor([-0.31233519], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 627
1500 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.4600179195404053

Iteration 16
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.031655896455049515
Worst bound: tensor([-0.06258512], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 609
1600 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.511861562728882

Iteration 17
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.06385532021522522
Worst bound: tensor([-0.02597779], device='cuda:0')
Total time: 0.0462  pickout: 0.0002 decision: 0.0008  bounding: 0.0447 add_domain: 0.0005
length of domains: 596
1700 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.5582289695739746

Iteration 18
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.05927498638629913
Worst bound: tensor([-0.01420456], device='cuda:0')
Total time: 0.0459  pickout: 0.0002 decision: 0.0008  bounding: 0.0444 add_domain: 0.0005
length of domains: 579
1800 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.604294776916504

Iteration 19
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03854576498270035
Worst bound: tensor([-0.07606900], device='cuda:0')
Total time: 0.0519  pickout: 0.0002 decision: 0.0008  bounding: 0.0504 add_domain: 0.0005
length of domains: 569
1900 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.656371831893921

Iteration 20
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03344548121094704
Worst bound: tensor([-0.05593222], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 555
2000 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.708217144012451

Iteration 21
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04011146351695061
Worst bound: tensor([-0.49181882], device='cuda:0')
Total time: 0.0517  pickout: 0.0002 decision: 0.0008  bounding: 0.0503 add_domain: 0.0005
length of domains: 545
2100 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.760141372680664

Iteration 22
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03407786786556244
Worst bound: tensor([-0.12744212], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 534
2200 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.811939239501953

Iteration 23
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03454652801156044
Worst bound: tensor([-0.08043951], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 515
2300 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.8637735843658447

Iteration 24
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.039524421095848083
Worst bound: tensor([-0.12249628], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 499
2400 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.9155685901641846

Iteration 25
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.07202570885419846
Worst bound: tensor([-0.29002362], device='cuda:0')
Total time: 0.0460  pickout: 0.0002 decision: 0.0008  bounding: 0.0445 add_domain: 0.0005
length of domains: 484
2500 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 3.9617373943328857

Iteration 26
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.07729990780353546
Worst bound: tensor([-0.10536712], device='cuda:0')
Total time: 0.0459  pickout: 0.0002 decision: 0.0008  bounding: 0.0445 add_domain: 0.0004
length of domains: 464
2600 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.007856130599976

Iteration 27
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.05718999728560448
Worst bound: tensor([-0.54447865], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 456
2700 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.059617757797241

Iteration 28
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.05400072783231735
Worst bound: tensor([-0.10122806], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 441
2800 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.111389875411987

Iteration 29
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04656055197119713
Worst bound: tensor([-0.43905103], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 430
2900 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.163149356842041

Iteration 30
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.0359186977148056
Worst bound: tensor([-0.16354549], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0004
length of domains: 408
3000 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.214867830276489

Iteration 31
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04904158413410187
Worst bound: tensor([-0.46583176], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 403
3100 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.26670241355896

Iteration 32
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.0734425038099289
Worst bound: tensor([-0.11575687], device='cuda:0')
Total time: 0.0457  pickout: 0.0002 decision: 0.0008  bounding: 0.0443 add_domain: 0.0005
length of domains: 387
3200 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.312658071517944

Iteration 33
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.0877675786614418
Worst bound: tensor([-0.56064731], device='cuda:0')
Total time: 0.0458  pickout: 0.0002 decision: 0.0008  bounding: 0.0443 add_domain: 0.0005
length of domains: 376
3300 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.358634948730469

Iteration 34
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.050003599375486374
Worst bound: tensor([-0.18277729], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 364
3400 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.4104063510894775

Iteration 35
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.06036917492747307
Worst bound: tensor([-0.29855156], device='cuda:0')
Total time: 0.0517  pickout: 0.0002 decision: 0.0008  bounding: 0.0502 add_domain: 0.0005
length of domains: 357
3500 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.462259531021118

Iteration 36
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.05848293751478195
Worst bound: tensor([-0.06431848], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 337
3600 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.513992547988892

Iteration 37
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.050254806876182556
Worst bound: tensor([-0.08254075], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 325
3700 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.565678358078003

Iteration 38
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.040219955146312714
Worst bound: tensor([-0.05015588], device='cuda:0')
Total time: 0.0514  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 307
3800 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.617335081100464

Iteration 39
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03912348300218582
Worst bound: tensor([-0.03865159], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 291
3900 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.6690354347229

Iteration 40
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.028428468853235245
Worst bound: tensor([-0.00959563], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 277
4000 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.7207207679748535

Iteration 41
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.021508965641260147
Worst bound: tensor([-0.00760365], device='cuda:0')
Total time: 0.0517  pickout: 0.0002 decision: 0.0008  bounding: 0.0503 add_domain: 0.0004
length of domains: 260
4100 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.772682189941406

Iteration 42
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.05193495750427246
Worst bound: tensor([-0.13505334], device='cuda:0')
Total time: 0.0457  pickout: 0.0002 decision: 0.0008  bounding: 0.0443 add_domain: 0.0005
length of domains: 240
4200 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.818619251251221

Iteration 43
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.0842738151550293
Worst bound: tensor([-0.54046917], device='cuda:0')
Total time: 0.0460  pickout: 0.0002 decision: 0.0008  bounding: 0.0445 add_domain: 0.0005
length of domains: 228
4300 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.86478328704834

Iteration 44
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.07374310493469238
Worst bound: tensor([-0.05988282], device='cuda:0')
Total time: 0.0458  pickout: 0.0002 decision: 0.0008  bounding: 0.0444 add_domain: 0.0005
length of domains: 215
4400 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.910786151885986

Iteration 45
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.06453510373830795
Worst bound: tensor([-0.09143460], device='cuda:0')
Total time: 0.0458  pickout: 0.0002 decision: 0.0008  bounding: 0.0444 add_domain: 0.0005
length of domains: 205
4500 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 4.956815242767334

Iteration 46
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04957546293735504
Worst bound: tensor([-0.36613381], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 190
4600 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 5.0085766315460205

Iteration 47
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.05464363098144531
Worst bound: tensor([-0.19411671], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 176
4700 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 5.060306787490845

Iteration 48
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04726187512278557
Worst bound: tensor([-0.13730460], device='cuda:0')
Total time: 0.0516  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 162
4800 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 5.112054824829102

Iteration 49
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.035344887524843216
Worst bound: tensor([-0.04017794], device='cuda:0')
Total time: 0.0514  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0004
length of domains: 144
4900 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 5.163664102554321

Iteration 50
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03298497200012207
Worst bound: tensor([-0.01094496], device='cuda:0')
Total time: 0.0514  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 125
5000 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 5.215327739715576

Iteration 51
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.04406890645623207
Worst bound: tensor([-0.25222552], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 119
5100 branch and bound domains visited
Current (lb-rhs): -0.8744577169418335
Cumulative time: 5.267019271850586

Iteration 52
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.037917885929346085
Worst bound: tensor([-0.24885738], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 106
5200 branch and bound domains visited
Current (lb-rhs): -0.37358760833740234
Cumulative time: 5.318732261657715

Iteration 53
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.026575159281492233
Worst bound: tensor([-0.02722561], device='cuda:0')
Total time: 0.0514  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 83
5300 branch and bound domains visited
Current (lb-rhs): -0.37358760833740234
Cumulative time: 5.3703694343566895

Iteration 54
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.03147193789482117
Worst bound: tensor([-0.14543986], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 70
5400 branch and bound domains visited
Current (lb-rhs): -0.37358760833740234
Cumulative time: 5.42205548286438

Iteration 55
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.033356159925460815
Worst bound: tensor([-0.07498205], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0501 add_domain: 0.0005
length of domains: 57
5500 branch and bound domains visited
Current (lb-rhs): -0.07498204708099365
Cumulative time: 5.4737749099731445

Iteration 56
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.030642691999673843
Worst bound: tensor([-0.02534050], device='cuda:0')
Total time: 0.0515  pickout: 0.0002 decision: 0.0008  bounding: 0.0500 add_domain: 0.0005
length of domains: 39
5600 branch and bound domains visited
Current (lb-rhs): -0.025340497493743896
Cumulative time: 5.525457143783569

Iteration 57
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.01971363089978695
Worst bound: tensor([-0.00436682], device='cuda:0')
Total time: 0.0473  pickout: 0.0002 decision: 0.0008  bounding: 0.0459 add_domain: 0.0005
length of domains: 22
5678 branch and bound domains visited
Current (lb-rhs): -0.004366815090179443
Cumulative time: 5.572959899902344

Iteration 58
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.01851254142820835
Worst bound: tensor([-0.00162613], device='cuda:0')
Total time: 0.0421  pickout: 0.0002 decision: 0.0008  bounding: 0.0406 add_domain: 0.0005
length of domains: 8
5722 branch and bound domains visited
Current (lb-rhs): -0.001626133918762207
Cumulative time: 5.615216970443726

Iteration 59
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 2.
Avg perturbation: 0.010283653624355793
Worst bound: tensor([-5.24520874e-06], device='cuda:0')
Total time: 0.0419  pickout: 0.0002 decision: 0.0008  bounding: 0.0405 add_domain: 0.0004
length of domains: 1
5738 branch and bound domains visited
Current (lb-rhs): -5.245208740234375e-06
Cumulative time: 5.657262325286865

Iteration 60
Batch size: 50
Using Linf sparse perturbation. Perturbed dimensions: 1.
Avg perturbation: 0.0036632921546697617
Worst bound: tensor([0.00017810], device='cuda:0')
Total time: 0.0381  pickout: 0.0001 decision: 0.0012  bounding: 0.0366 add_domain: 0.0002
length of domains: 0
5742 branch and bound domains visited
No domains left, verification finished!
The lower bound of last batch is 0.7353813052177429
Cumulative time: 5.695499420166016

Result: unsat
Time: 94.2453043460846
